{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import regularily generated 7-day average flow data from USGS shapefile and export a formatted shapefile with correct labels for the streams with new low flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing arcpy\n"
     ]
    }
   ],
   "source": [
    "# Import arcpy and other modules\n",
    "print(\"importing arcpy\")\n",
    "import arcpy \n",
    "from arcpy import env \n",
    "from arcpy.sa import *\n",
    "from urllib.request import *\n",
    "import time\n",
    "import tarfile\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today = time.strftime(\"%Y%m%d\")\n",
    "url = 'http://waterwatch.usgs.gov/downloads/cov_shps/pa07dstx_shp.tar.gz'\n",
    "path = 'N:\\\\Projects\\\\Drought\\\\' \n",
    "outpath = path+'archive\\\\USGS_waterwatch_'+today+'_pa07dstx_shp'\n",
    "outshape = path+'\\\\shapes\\\\USGS_7day_flow_ca_'+today+'.shp'\n",
    "outshape_final = path+'\\\\shapes\\\\USGS_7day_flow_ca_'+today+'_final.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading USGS shapefile  to N:\\Projects\\Drought\\archive\\USGS_waterwatch_20161205_pa07dstx_shp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('N:\\\\Projects\\\\Drought\\\\archive\\\\USGS_waterwatch_20161205_pa07dstx_shp.tar.gz',\n",
       " <http.client.HTTPMessage at 0xd68c940>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the latest shapefile from http://waterwatch.usgs.gov/downloads/cov_shps/pa07dstx_shp.tar.gz\n",
    "\n",
    "print(\"Downloading USGS shapefile  to \"+outpath)\n",
    "urlretrieve(url, outpath+'.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting USGS shapefile\n"
     ]
    }
   ],
   "source": [
    "# Extract the shapefile\n",
    "print(\"Extracting USGS shapefile\")\n",
    "tar = tarfile.open(outpath+'.tar.gz')\n",
    "tar.extractall(outpath)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting California records and reprojecting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\shapes\\\\USGS_7day_flow_ca_20161205.shp'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the California records and reproject to California Albers\n",
    "print(\"Selecting California records and reprojecting\")\n",
    "arcpy.FeatureClassToFeatureClass_conversion(outpath+'\\\\pa07dstx.shp',path+'\\\\temp','pa07dstx_ca_'+today+'.shp',' \"ST\" = \\'ca\\' ')\n",
    "wgs84 = arcpy.SpatialReference(\"WGS 1984\")\n",
    "albers = arcpy.SpatialReference(\"NAD 1983 California (Teale) Albers (Meters)\")\n",
    "arcpy.DefineProjection_management(path+'\\\\temp\\\\pa07dstx_ca_'+today+'.shp',wgs84)\n",
    "\n",
    "arcpy.Project_management(path+'\\\\temp\\\\pa07dstx_ca_'+today+'.shp', outshape, albers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating the gage labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\shapes\\\\USGS_7day_flow_ca_20161205.shp'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update the gage name to a label\n",
    "print (\"Updating the gage labels\")\n",
    "arcpy.AddField_management(outshape, \"Label\", \"TEXT\", \"\",\"\",200)\n",
    "expression = \"replace_all(!STANAME!)\"\n",
    "codeblock =\"\"\"def replace_all(text):\n",
    "    dic = {' NR ':' NEAR ',\n",
    "           ' NR. ':' NEAR ',\n",
    "           ' AB ':' ABOVE ',\n",
    "           ' ABV ':' ABOVE ',\n",
    "           ' BL ':' BELOW ',\n",
    "           ' BLW ':' BELOW ',\n",
    "           ' R ':' RIVER ',\n",
    "           ' RV ':' RIVER ',\n",
    "           ' RVR ':' RIVER ',\n",
    "           ' TRIB ':' TRIBUTARY ',\n",
    "           ' SL ':' SLOUGH ',\n",
    "           ' C ':' CREEK ',\n",
    "           ' CK ':' CREEK ',\n",
    "           ' CR ':' CREEK ',\n",
    "            ' CR N ':' CREEK NEAR ',\n",
    "           ' CH ':' CHANNEL ',\n",
    "           ' CHAN ':' CHANNEL ',\n",
    "           ' CNL ':' CANAL ',\n",
    "           ' CN ':' CANAL ',\n",
    "           ' FL ' : ' FLUME ',\n",
    "           ' D ' : ' DRAIN ',\n",
    "           ' DR ':' DRAIN ',\n",
    "           ' FLD ' : ' FLOOD ',\n",
    "           ' A ':' AT ',\n",
    "           ' MF ':' MIDDLE FORK ',\n",
    "           ' SF ':' SOUTH FORK ',\n",
    "           ' NF ':' NORTH FORK ',\n",
    "           ' EF ':' EAST FORK ',\n",
    "           ' WF ':' WEST FORK ',\n",
    "           'E FK ':'EAST FORK ',\n",
    "           'W FK ':'WEST FORK ',\n",
    "           ' FK ': ' FORK ',\n",
    "           ' F ': ' FORK ',\n",
    "           ' W ': ' WEST ',\n",
    "           ' N ': ' NORTH ',\n",
    "           ' E ': ' EAST ',\n",
    "           ' S ': ' SOUTH ',\n",
    "           ' BR ':' BRIDGE ',\n",
    "           ' HWY ':' HIGHWAY ',\n",
    "           ' ST ':' STREET ',\n",
    "           ' RD ':' ROAD ',\n",
    "           ' PKWY ':' PARKWAY ',\n",
    "           ' SPG ':' SPRING ',\n",
    "           ' SPR ':' SPRING ',\n",
    "           ' SP ':' SPRING ',\n",
    "           ' SPGS, ':' SPRINGS, ',\n",
    "           ' CYN ':' CANYON ',\n",
    "           ' LK ':' LAKE ',\n",
    "           ' LKS ':' LAKES ',\n",
    "           ' ISL ':' ISLAND ',\n",
    "           ' V ':' VALLEY ',\n",
    "           ' MTN ':' MOUNTAIN ',\n",
    "           ' SND ':' SAND ',\n",
    "           ' PH ':' POWER HOUSE ',\n",
    "           ' IT ':' INTAKE ',\n",
    "           ' OTLT ':' OUTLET ',\n",
    "           ' OL ':' OUTLET ',\n",
    "           ' CO ':' COMPANY ',\n",
    "           ' PT ':' POINT ',\n",
    "           ' BAS ':' BASIN ',\n",
    "           ' RES ':' RESERVOIR ',\n",
    "           ' RE ':' RESERVOIR ',\n",
    "           ' LO ':' LOWER ',\n",
    "           ' L ':' LOWER ',\n",
    "           ' UP ':' UPPER ',\n",
    "           ' DIV ':' DIVERSION ',\n",
    "           ' DIVER ':' DIVERSION ',\n",
    "           ' TU ' : ' TUNNEL ',\n",
    "           ' PROJ ' : ' PROJECT ',\n",
    "           ' BNDRY ': ' BOUNDRY ',\n",
    "           ' PERC ': ' PERCOLATION ',\n",
    "           ' IRR ':' IRRIGATION ',\n",
    "           ' IRRIG ':' IRRIGATION ',\n",
    "           ' FW RL ':' FRESHWATER RELEASE ',\n",
    "           ' REL ':' RELEASE ',\n",
    "           ' CTRL ':' CONTROLLED ',\n",
    "           ' FRM ':' FROM ',\n",
    "           ' ID ' : ' IRRIGATION DISTRICT ',\n",
    "           'PVID' : 'PALO VERDE IRRIGATION DISTRICT',\n",
    "           'P.V.I.D.' : 'PALO VERDE IRRIGATION DISTRICT',\n",
    "           'P.P.' : 'POWER PLANT',\n",
    "           ' PP ' : ' POWER PLANT ',\n",
    "           'SDPP' : 'SIPHON DROP POWER PLANT',\n",
    "           'DIV.' : 'DIVERSION',\n",
    "           'YMCWW' : 'YUMA MAIN CANAL WASTEWAY',\n",
    "           ' WW ' : ' WASTEWAY ',\n",
    "           'DR0P' : 'DROP',\n",
    "           'EB CA AQUEDUCT' : 'EAST BRANCH CALIFORNIA AQUEDUCT',\n",
    "           ' CA AQUEDUCT ' : ' CALIFORNIA AQUEDUCT ',\n",
    "           'CA AQ XING' : 'CALIFORNIA AQUEDUCT CROSSING',\n",
    "           'EDWARDS AFB' : 'EDWARDS AIRFORCE BASE',\n",
    "           ' WC ' : ' WATER COMPANY ',\n",
    "           ' UWC ' : ' UNION WATER COMPANY ',\n",
    "           ' CWD ' : ' COUNTY WATER DISTRICT ',\n",
    "           'MC GEE' : 'MCGEE',\n",
    "           'UP CONWAY D' : 'UPPER CONWAY DITCH',\n",
    "           'TRCKEE' : 'TRUCKEE',\n",
    "           ' TRU. ' : ' TRUCKEE' ,\n",
    "           'FT DS' : 'FEET DOWNSTREAM',\n",
    "           'UTICA CA' : 'UTICA CANYON',\n",
    "           ' AZ-CAL' : ' AZ-CA',\n",
    "           ' D PRES ' : ' DEL PRESIDIO ',\n",
    "           ' COND ' : ' CONDUIT ',\n",
    "           'BAKRSFLD' : 'BAKERSFIELD',\n",
    "           'JCK.MDW' : 'JACKSON MEADOWS',\n",
    "           'WQCP' : 'WATER QUALITY CONTROL PLANT',           \n",
    "           }\n",
    "    # Replace all the abbreviations\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "\n",
    "    # Replace certain letters  at the front of the string with replacements\n",
    "    if text.startswith('W '):\n",
    "        text = 'WEST '+text[2:]\n",
    "    elif text.startswith('E '):\n",
    "        text = 'EAST '+text[2:]\n",
    "    elif text.startswith('N '):\n",
    "        text = 'NORTH '+text[2:]\n",
    "    elif text.startswith('S '):\n",
    "        text = 'SOUTH '+text[2:]\n",
    "    elif text.startswith('L '):\n",
    "        text = 'LOWER '+text[2:]\n",
    "    elif text.startswith('M '):\n",
    "        text = 'MIDDLE '+text[2:]\n",
    "    elif text.startswith('EF '):\n",
    "        text = 'EAST FORK '+text[3:]\n",
    "    elif text.startswith('WF '):\n",
    "        text = 'WEST FORK '+text[3:]\n",
    "    elif text.startswith('MF '):\n",
    "        text = 'MIDDLE FORK '+text[3:]\n",
    "    elif text.startswith('SF '):\n",
    "        text = 'SOUTH FORK '+text[3:]\n",
    "    elif text.startswith('NF '):\n",
    "        text = 'NORTH FORK '+text[3:]\n",
    "    elif text.startswith('SB '):\n",
    "        text = 'SOUTH BRANCH '+text[3:]\n",
    "    elif text.startswith('NB '):\n",
    "        text = 'NORTH BRANCH '+text[3:]\n",
    "    elif text.startswith('EB '):\n",
    "        text = 'EAST BRANCH '+text[3:]\n",
    "    elif text.startswith('WB '):\n",
    "        text = 'WEST BRANCH '+text[3:]\n",
    "    elif text.startswith('LK '):\n",
    "        text = 'LAKE '+text[3:]\n",
    "    elif text.startswith('UP '):\n",
    "        text = 'UPPER '+text[3:]\n",
    "    elif text.startswith('CA '):\n",
    "        text = 'CALIFORNIA '+text[3:]\n",
    "    elif text.startswith('JW '):\n",
    "        text = 'J.W. '+text[3:]\n",
    "    elif text.startswith('LO '):\n",
    "        text = 'LOWER '+text[3:]\n",
    "    elif text.startswith('DIV '):\n",
    "        text = 'DIVERSION '+text[4:]\n",
    "    elif text.startswith('SCE '):\n",
    "        text = 'SOUTHERN CALIFORNIA EDDISON '+text[4:]\n",
    "    elif text.startswith('PGE '):\n",
    "        text = 'PACIFIC GAS AND ELECTRIC '+text[4:]\n",
    "    else:\n",
    "        text = text\n",
    "\n",
    "    #Convert to title case\n",
    "    text = text.title()\n",
    "    \n",
    "    # Change the capitalization of some of the words\n",
    "    dic2 = {' Near ':' near ',\n",
    "            ' Above ':' above ',\n",
    "            ' Below ':' below ',\n",
    "            ' Opposite ':' opposite ',\n",
    "            ' At ':' at ',\n",
    "            ' Of ':' of ',\n",
    "            ' Ca-Az':' CA-AZ',\n",
    "            ' Az-Ca':' AZ-CA',\n",
    "            ' Az-Cal':' AZ-CA',\n",
    "            '-Ariz.-Calif':', AZ-CA',\n",
    "            ' Ariz. Calif.':' AZ-CA',\n",
    "            ' Cwc ':' CWC ',\n",
    "            ' Mwc ':' MWC ',\n",
    "            }\n",
    "    for i, j in dic2.items():\n",
    "        text = text.replace(i, j)\n",
    "\n",
    "    # Capitalize state name at the end of the string\n",
    "    if text.endswith(' Ca'):\n",
    "        text = text[:-3]+', CA'\n",
    "    elif text.endswith(' Az'):\n",
    "        text = text[:-3]+', AZ'\n",
    "    elif text.endswith(' Nv'):\n",
    "        text = text[:-3]+', NV'\n",
    "    else:\n",
    "        text = text\n",
    "\n",
    "    # Replace any double commas with a single comma\n",
    "    text = text.replace(',,',',')\n",
    "\n",
    "    # Add parenthesis around the second clause starting with the first near above below or at\n",
    "    paren_list = [text.find(' above '),text.find(' near '),text.find(' at '),text.find(' below '),text.find(' opposite ')]\n",
    "    if max(paren_list) == -1:\n",
    "        text = text\n",
    "    else:\n",
    "        neg1_count = paren_list.count(-1)\n",
    "        for x in range(0,neg1_count):\n",
    "            paren_list.remove(-1)\n",
    "        paren = min(paren_list)\n",
    "        text = text[:(paren + 1)]+'('+text[(paren + 1):]+')'\n",
    "    \n",
    "    return text\"\"\" \n",
    "\n",
    "arcpy.CalculateField_management(outshape, \"Label\", expression, \"PYTHON_9.3\", codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\shapes\\\\USGS_7day_flow_ca_20161205.shp'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new field and add the class names to the field\n",
    "arcpy.AddField_management(outshape, \"Class_Name\", \"TEXT\", \"\",\"\",50)\n",
    "\n",
    "expression = \"reclass(!CLASS!)\"\n",
    "codeblock = \"\"\"\n",
    "def reclass(cls):\n",
    "    if (cls == 1):\n",
    "        return \"New Low\"\n",
    "    elif (cls == 2):\n",
    "        return \"Much Below Normal\"\n",
    "    elif (cls == 3):\n",
    "        return \"Much Below Normal\"\n",
    "    elif (cls == 4):\n",
    "        return \"Below Normal\"\n",
    "    elif (cls == 5):\n",
    "        return \"Normal\"\n",
    "    elif (cls == 6):\n",
    "        return \"Above Normal\"\n",
    "    elif (cls == 7):\n",
    "        return \"Much Above Normal\"\n",
    "    elif (cls == 8):\n",
    "        return \"New High\"\n",
    "    else:\n",
    "        return \"Not Ranked\"\n",
    "\"\"\"\n",
    "arcpy.CalculateField_management(outshape, \"Class_Name\", expression, \"PYTHON_9.3\", codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\shapes\\\\USGS_7day_flow_ca_20161205.shp'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new field for the River Name only\n",
    "arcpy.AddField_management(outshape, \"River_Name\", \"TEXT\", \"\",\"\",50)\n",
    "\n",
    "expression = \"label_split(!Label!)\"\n",
    "codeblock = \"\"\"\n",
    "def label_split(label):\n",
    "    text = label.split(\" (\")\n",
    "    return text[0]\n",
    "\"\"\"\n",
    "arcpy.CalculateField_management(outshape, \"River_Name\", expression, \"PYTHON_9.3\", codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\shapes\\\\USGS_7day_flow_ca_20161205.shp'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new field for the Gage location only\n",
    "arcpy.AddField_management(outshape, \"Gage_Loc\", \"TEXT\", \"\",\"\",150)\n",
    "\n",
    "expression = \"label_split(!Label!)\"\n",
    "codeblock = \"\"\"\n",
    "def label_split(label):\n",
    "    text = label.split(\" (\")\n",
    "    if (len(text)>1):\n",
    "        return \"(\"+text[1]\n",
    "    else:\n",
    "        return label\n",
    "\"\"\"\n",
    "arcpy.CalculateField_management(outshape, \"Gage_Loc\", expression, \"PYTHON_9.3\", codeblock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\shapes\\\\USGS_7day_flow_ca_20161205_final.shp'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add strategy and ecological value to the gage locations based on huc12 watershed values\n",
    "join_features = path + \"\\\\gdbs\\\\Rivers_at_Risk.gdb\\\\water_rights_huc12\"\n",
    "\n",
    "arcpy.SpatialJoin_analysis(outshape, join_features, outshape_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to geodatabase\n",
      "Exporting to CSV\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'N:\\\\Projects\\\\Drought\\\\\\\\tables\\\\USGS_7day_flow_ca.csv'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export to tables\n",
    "print (\"Exporting to geodatabase\")\n",
    "arcpy.TableToTable_conversion(outshape_final, path+\"\\\\gdbs\\\\Rivers_at_Risk.gdb\", 'USGS_7day_flow_ca')\n",
    "\n",
    "print (\"Exporting to CSV\")\n",
    "arcpy.TableToTable_conversion(outshape_final, path+\"\\\\tables\", 'USGS_7day_flow_ca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading historical stream flow comparision to N:\\Projects\\Drought\\\\tables\\USGS_historic_flow.csv\n"
     ]
    }
   ],
   "source": [
    "# Download statewide summaries of flow classes from http://waterwatch.usgs.gov/ww_cont.php?m=pa07d&w=table&r=ca&a=1\n",
    "# Another optionhttp://waterwatch.usgs.gov/tables/pa07a/pa07a_ca.xls\n",
    "print (\"Downloading historical stream flow comparision to \"+path+\"\\\\tables\\\\USGS_historic_flow.csv\")\n",
    "page = urlopen('http://waterwatch.usgs.gov/ww_cont.php?m=pa07d&w=table&r=ca&a=1')\n",
    "page_content = page.readlines()\n",
    "\n",
    "class_list = [\"New Low\",\"Much Below Normal\",\"Below Normal\",\"Normal\",\"Above Normal\",\"Much Above Normal\",\"New High\"]\n",
    "f = open(path+'\\\\tables\\\\USGS_historic_flow.csv', 'w')\n",
    "f.write(\"Date,Class,Class Name,Percent in Class,Total Stations\\n\")\n",
    "for i in range(47,len(page_content)-5):\n",
    "    line = page_content[i].split()\n",
    "    for j in range(1,8):\n",
    "        f.write(line[0].decode(\"utf-8\")+\",\"+str(j)+\",\"+class_list[(j-1)]+\",\"+str(int(line[j].decode(\"utf-8\"))*.01)+\",\"+line[8].decode(\"utf-8\")+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a new table with only the percent below normal for the most recent value\n",
    "f = open(path+'\\\\tables\\\\Recent_below_normal.csv', 'w') ;\\\n",
    "f.write(\"Date,Percent Below Normal\\n\");\\\n",
    "line = page_content[(len(page_content)-6)].split();\\\n",
    "f.write(line[0].decode(\"utf-8\")+\",\"+str((int(line[1].decode(\"utf-8\"))+int(line[2].decode(\"utf-8\"))+int(line[3].decode(\"utf-8\")))*.01)+\"\\n\");\\\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete N:\\Projects\\Drought\\gdbs\\Rivers_at_Risk.mdb\\USGS_7day_flow_ca\n",
      "Copy N:\\Project\\Drought\\gdbs\\Rivers_at_Risk.gdb\\USGS_7day_flow_ca into C:\\Arcscratch\\Drought\\gdbs\\Rivers_at_Risk.mdb\n"
     ]
    }
   ],
   "source": [
    "print(r\"Delete N:\\Projects\\Drought\\gdbs\\Rivers_at_Risk.mdb\\USGS_7day_flow_ca\")\n",
    "print(r\"Copy N:\\Project\\Drought\\gdbs\\Rivers_at_Risk.gdb\\USGS_7day_flow_ca into C:\\Arcscratch\\Drought\\gdbs\\Rivers_at_Risk.mdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
